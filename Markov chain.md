1. Markov chain; a process for which predictions can be made regarding future outcomes based solely on its present state and—most importantly—such predictions are just as good as the ones that could be made knowing the process's full history.^[https://en.wikipedia.org/wiki/Markov_chain#cite_note-:3-12]

# related
1. [[Markov property]]