1. intelligence → gravity
	1. intelligence is like gravity: it emanates from its point(s) of influence and (usually) becomes weaker farther away from them
		1. analogous to extended mind thesis
			1. interference1=[[gravitational potential energy]] → why (not)?
# [[information]]
1. heavy weighing factors causing external [[information]] (not stored in one's long-term [[human memory]]) to not contribute much to one's intelligence
	1. high latency
	2. less quantity of [[information]] (e.g. [[brain]] makes from "A" and "B" → "AB")
3. do you have to know beforehand why you want to ask something? + why
	1. not necessarily → sometimes just increasing the quantity/accuracy of manipulable [[information]] is enough → increase future freedom of action
		1. e.g. you don't know (everything) either what you can do with the knowledge you acquire (in [[spaced repetition|SRS]])

# high intelligence
1. high intelligence → "simple" questions are complicated
	1. This is why high+ gifted people often seem so out of sync with those around them. The question “how are you today?” can feel extremely complex (How am I about which aspect of my life? Why are you asking? How should I be? and so on)
2. positive correlation between [[emotion|emotional]] intensity and intelligence (especially in girls)?
	1. e.g. ProjektMelody, Hanna Freriks, yourself, Anne-Lynn de Kock
	2. better [[neurophysiology|hardware]] → increases intensity of all?

# intelligence formula
1. intelligence → [[entropy]]
	1. higher intelligence decreases local [[entropy]] more quickly/efficiently
2. intelligence formula → [[exploration-exploitation trade-off]]
	1. usually, the fewer the (future) options, the more one should (or is) exploit
	2. the more options you can eliminate (not necessarily future ones), the faster one can go from exploration to exploitation e.g. [[dating]]

## process
1. maximizing intelligence → converging criticalities
	1. you can try to make use of both product and [[process optimalism]] → sometimes, this requires many **more** converging criticalities to end up with a situation with enough/most options

## negative
### [[extended mind]]
1. what does creating too many connections (e.g. [[Obsidian.md]]) do to the "intelligence formula" and its components?
	1. it might raise the potential options, but decreases how many you can utilize (∇Sτ)
		1. organization is important
		2. how can you figure out whether this is likely to be the case or not?
			1. [[adaptive replacement cache]] → including the nearby (inside-out) concepts you are indirectly connecting to
				1. the most connected ones usually reside in the highest [[cache]] hierarchy and you also want these units to increase intelligence the most
	2. **related**
		1. [[connectivity noise]]

# related
1. [[collective intelligence]]